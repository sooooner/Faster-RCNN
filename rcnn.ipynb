{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "identified-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "reliable-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./res/train_df.csv')\n",
    "image = cv2.imread('./res/train_imgs/001-1-1-01-Z17_A-0000001.jpg', cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "about-produce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 1920, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "brave-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x_min'] = df.iloc[:, 1:49:2].apply(lambda x: int(min(x)), axis=1)\n",
    "df['x_max'] = df.iloc[:, 1:49:2].apply(lambda x: int(max(x)), axis=1)\n",
    "df['y_min'] = df.iloc[:, 2:49:2].apply(lambda x: int(min(x)), axis=1)\n",
    "df['y_max'] = df.iloc[:, 2:49:2].apply(lambda x: int(max(x)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ordered-movie",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>nose_x</th>\n",
       "      <th>nose_y</th>\n",
       "      <th>left_eye_x</th>\n",
       "      <th>left_eye_y</th>\n",
       "      <th>right_eye_x</th>\n",
       "      <th>right_eye_y</th>\n",
       "      <th>left_ear_x</th>\n",
       "      <th>left_ear_y</th>\n",
       "      <th>right_ear_x</th>\n",
       "      <th>...</th>\n",
       "      <th>spine1(waist)_x</th>\n",
       "      <th>spine1(waist)_y</th>\n",
       "      <th>left_instep_x</th>\n",
       "      <th>left_instep_y</th>\n",
       "      <th>right_instep_x</th>\n",
       "      <th>right_instep_y</th>\n",
       "      <th>x_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_min</th>\n",
       "      <th>y_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001-1-1-01-Z17_A-0000001.jpg</td>\n",
       "      <td>1046.389631</td>\n",
       "      <td>344.757881</td>\n",
       "      <td>1041.655294</td>\n",
       "      <td>329.820225</td>\n",
       "      <td>1059.429507</td>\n",
       "      <td>334.484230</td>\n",
       "      <td>1020.117796</td>\n",
       "      <td>338.890539</td>\n",
       "      <td>1048.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1026.515770</td>\n",
       "      <td>514.054730</td>\n",
       "      <td>998.578836</td>\n",
       "      <td>826.718013</td>\n",
       "      <td>1063.204067</td>\n",
       "      <td>838.827465</td>\n",
       "      <td>956</td>\n",
       "      <td>1134</td>\n",
       "      <td>316</td>\n",
       "      <td>838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001-1-1-01-Z17_A-0000003.jpg</td>\n",
       "      <td>1069.850679</td>\n",
       "      <td>340.711494</td>\n",
       "      <td>1058.608552</td>\n",
       "      <td>324.593690</td>\n",
       "      <td>1075.242111</td>\n",
       "      <td>325.593690</td>\n",
       "      <td>1041.422997</td>\n",
       "      <td>331.694815</td>\n",
       "      <td>1065.593682</td>\n",
       "      <td>...</td>\n",
       "      <td>1058.766231</td>\n",
       "      <td>508.797029</td>\n",
       "      <td>1002.265676</td>\n",
       "      <td>699.062706</td>\n",
       "      <td>1066.376234</td>\n",
       "      <td>841.499445</td>\n",
       "      <td>974</td>\n",
       "      <td>1144</td>\n",
       "      <td>323</td>\n",
       "      <td>841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001-1-1-01-Z17_A-0000005.jpg</td>\n",
       "      <td>1084.475902</td>\n",
       "      <td>337.000008</td>\n",
       "      <td>1078.717997</td>\n",
       "      <td>323.757889</td>\n",
       "      <td>1095.648412</td>\n",
       "      <td>325.242119</td>\n",
       "      <td>1061.039884</td>\n",
       "      <td>329.351571</td>\n",
       "      <td>1086.461032</td>\n",
       "      <td>...</td>\n",
       "      <td>1052.844144</td>\n",
       "      <td>495.890539</td>\n",
       "      <td>989.437847</td>\n",
       "      <td>808.757889</td>\n",
       "      <td>1066.071417</td>\n",
       "      <td>841.749554</td>\n",
       "      <td>984</td>\n",
       "      <td>1163</td>\n",
       "      <td>319</td>\n",
       "      <td>841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001-1-1-01-Z17_A-0000007.jpg</td>\n",
       "      <td>1042.320047</td>\n",
       "      <td>361.452689</td>\n",
       "      <td>1037.907194</td>\n",
       "      <td>344.117804</td>\n",
       "      <td>1050.328382</td>\n",
       "      <td>353.913729</td>\n",
       "      <td>1016.844144</td>\n",
       "      <td>340.913737</td>\n",
       "      <td>1042.164191</td>\n",
       "      <td>...</td>\n",
       "      <td>990.375124</td>\n",
       "      <td>507.624866</td>\n",
       "      <td>1001.305177</td>\n",
       "      <td>829.233767</td>\n",
       "      <td>1159.516499</td>\n",
       "      <td>599.389997</td>\n",
       "      <td>941</td>\n",
       "      <td>1159</td>\n",
       "      <td>328</td>\n",
       "      <td>829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001-1-1-01-Z17_A-0000009.jpg</td>\n",
       "      <td>1058.046395</td>\n",
       "      <td>343.164191</td>\n",
       "      <td>1046.717997</td>\n",
       "      <td>331.703163</td>\n",
       "      <td>1058.132650</td>\n",
       "      <td>331.781079</td>\n",
       "      <td>1031.258806</td>\n",
       "      <td>338.593690</td>\n",
       "      <td>1049.812620</td>\n",
       "      <td>...</td>\n",
       "      <td>1034.391088</td>\n",
       "      <td>510.843791</td>\n",
       "      <td>998.625231</td>\n",
       "      <td>805.218921</td>\n",
       "      <td>1059.625956</td>\n",
       "      <td>839.765102</td>\n",
       "      <td>961</td>\n",
       "      <td>1132</td>\n",
       "      <td>331</td>\n",
       "      <td>839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          image       nose_x      nose_y   left_eye_x  \\\n",
       "0  001-1-1-01-Z17_A-0000001.jpg  1046.389631  344.757881  1041.655294   \n",
       "1  001-1-1-01-Z17_A-0000003.jpg  1069.850679  340.711494  1058.608552   \n",
       "2  001-1-1-01-Z17_A-0000005.jpg  1084.475902  337.000008  1078.717997   \n",
       "3  001-1-1-01-Z17_A-0000007.jpg  1042.320047  361.452689  1037.907194   \n",
       "4  001-1-1-01-Z17_A-0000009.jpg  1058.046395  343.164191  1046.717997   \n",
       "\n",
       "   left_eye_y  right_eye_x  right_eye_y   left_ear_x  left_ear_y  right_ear_x  \\\n",
       "0  329.820225  1059.429507   334.484230  1020.117796  338.890539  1048.000000   \n",
       "1  324.593690  1075.242111   325.593690  1041.422997  331.694815  1065.593682   \n",
       "2  323.757889  1095.648412   325.242119  1061.039884  329.351571  1086.461032   \n",
       "3  344.117804  1050.328382   353.913729  1016.844144  340.913737  1042.164191   \n",
       "4  331.703163  1058.132650   331.781079  1031.258806  338.593690  1049.812620   \n",
       "\n",
       "   ...  spine1(waist)_x  spine1(waist)_y  left_instep_x  left_instep_y  \\\n",
       "0  ...      1026.515770       514.054730     998.578836     826.718013   \n",
       "1  ...      1058.766231       508.797029    1002.265676     699.062706   \n",
       "2  ...      1052.844144       495.890539     989.437847     808.757889   \n",
       "3  ...       990.375124       507.624866    1001.305177     829.233767   \n",
       "4  ...      1034.391088       510.843791     998.625231     805.218921   \n",
       "\n",
       "   right_instep_x  right_instep_y  x_min  x_max  y_min  y_max  \n",
       "0     1063.204067      838.827465    956   1134    316    838  \n",
       "1     1066.376234      841.499445    974   1144    323    841  \n",
       "2     1066.071417      841.749554    984   1163    319    841  \n",
       "3     1159.516499      599.389997    941   1159    328    829  \n",
       "4     1059.625956      839.765102    961   1132    331    839  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-albuquerque",
   "metadata": {},
   "source": [
    "# Faster R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-chaos",
   "metadata": {},
   "source": [
    "## backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-thesaurus",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ruled-ratio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet = tf.keras.applications.resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-annex",
   "metadata": {},
   "source": [
    "### VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "expired-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(image.shape))\n",
    "vgg = tf.keras.applications.VGG19(\n",
    "    include_top=False,\n",
    "    weights='imagenet', \n",
    "    input_tensor=inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "finnish-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map = vgg(tf.expand_dims(tf.ones_like(image), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "liked-trustee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1080, 1920, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 1080, 1920, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 1080, 1920, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 540, 960, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 540, 960, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 540, 960, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 270, 480, 128)     0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 270, 480, 256)     295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 270, 480, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 270, 480, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 270, 480, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 135, 240, 256)     0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 135, 240, 512)     1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 135, 240, 512)     2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 135, 240, 512)     2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 135, 240, 512)     2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 67, 120, 512)      0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 67, 120, 512)      2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 67, 120, 512)      2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 67, 120, 512)      2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 67, 120, 512)      2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 33, 60, 512)       0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-conspiracy",
   "metadata": {},
   "source": [
    "## Region Proposal Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-invention",
   "metadata": {},
   "source": [
    "### Anchor boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "endless-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anchor_box_generator(x, y):\n",
    "    ratio = [(1, 1), (2, 1), (1, 2)]\n",
    "    scales = [64, 128, 256]\n",
    "    anchor_boxes = []\n",
    "    for scale in scales:\n",
    "        for w, h in ratio:\n",
    "            w *= scale\n",
    "            h *= scale\n",
    "            \n",
    "            x1 = x - w/2\n",
    "            x2 = x + w/2\n",
    "            \n",
    "            y1 = y - h/2\n",
    "            y2 = y + h/2\n",
    "            anchor_boxes.append([x1, x2, y1, y2])\n",
    "        \n",
    "    return anchor_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "attempted-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Anchor_Boxes(w=33, h=60, img_shape=(1080, 1920)):\n",
    "    anchor_boxes = []\n",
    "    for x in range(image.shape[0]//w//2, img_shape[0], image.shape[0]//w):\n",
    "        for y in range(image.shape[1]//h//2, img_shape[1], image.shape[1]//h):\n",
    "            anchor_boxes.append(anchor_box_generator(x, y))\n",
    "    return np.array(anchor_boxes).reshape(-1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dated-bristol",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_boxes = Anchor_Boxes(w=image.shape[0]//2**4, h=image.shape[1]//2**4, img_shape=image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "amino-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = df.iloc[:,:1].copy() \n",
    "ground_truth['x_min'] = df['x_min'] - (df['x_max'] - df['x_min'])*.05\n",
    "ground_truth['x_max'] = df['x_max'] + (df['x_max'] - df['x_min'])*.05\n",
    "ground_truth['y_min'] = df['y_min'] - (df['y_max'] - df['y_min'])*.05\n",
    "ground_truth['y_max'] = df['y_max'] + (df['y_max'] - df['y_min'])*.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "indian-wyoming",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>x_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_min</th>\n",
       "      <th>y_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4190</th>\n",
       "      <td>642-2-4-31-Z148_E-0000023.jpg</td>\n",
       "      <td>590.95</td>\n",
       "      <td>1142.05</td>\n",
       "      <td>157.10</td>\n",
       "      <td>924.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4191</th>\n",
       "      <td>642-2-4-31-Z148_E-0000025.jpg</td>\n",
       "      <td>590.95</td>\n",
       "      <td>1142.05</td>\n",
       "      <td>296.75</td>\n",
       "      <td>918.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4192</th>\n",
       "      <td>642-2-4-31-Z148_E-0000027.jpg</td>\n",
       "      <td>590.95</td>\n",
       "      <td>1142.05</td>\n",
       "      <td>296.75</td>\n",
       "      <td>918.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193</th>\n",
       "      <td>642-2-4-31-Z148_E-0000029.jpg</td>\n",
       "      <td>590.95</td>\n",
       "      <td>1142.05</td>\n",
       "      <td>296.75</td>\n",
       "      <td>918.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4194</th>\n",
       "      <td>642-2-4-31-Z148_E-0000031.jpg</td>\n",
       "      <td>589.90</td>\n",
       "      <td>1164.10</td>\n",
       "      <td>296.75</td>\n",
       "      <td>918.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              image   x_min    x_max   y_min   y_max\n",
       "4190  642-2-4-31-Z148_E-0000023.jpg  590.95  1142.05  157.10  924.90\n",
       "4191  642-2-4-31-Z148_E-0000025.jpg  590.95  1142.05  296.75  918.25\n",
       "4192  642-2-4-31-Z148_E-0000027.jpg  590.95  1142.05  296.75  918.25\n",
       "4193  642-2-4-31-Z148_E-0000029.jpg  590.95  1142.05  296.75  918.25\n",
       "4194  642-2-4-31-Z148_E-0000031.jpg  589.90  1164.10  296.75  918.25"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-estonia",
   "metadata": {},
   "source": [
    "### IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "silent-litigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(box1, box2, eps=1e-5):\n",
    "    box1_area = (box1[1] - box1[0] + 1) * (box1[3] - box1[2] + 1)\n",
    "    box2_area = (box2[1] - box2[0] + 1) * (box2[3] - box2[2] + 1)\n",
    "    \n",
    "    x1 = max(box1[0], box2[0])\n",
    "    x2 = min(box1[1], box2[1])\n",
    "    \n",
    "    y1 = max(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])    \n",
    "    \n",
    "    h = max(0.0, y2 - y1 + 1)\n",
    "    w = max(0.0, x2 - x1 + 1)\n",
    "    \n",
    "    if (w <= 0) or (h <= 0):\n",
    "        return 0.0\n",
    "    \n",
    "    intersect = h * w\n",
    "    union = box1_area + box2_area - intersect\n",
    "    \n",
    "    iou = intersect / (union + eps)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-sierra",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "atlantic-father",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import Parallel, delayed\n",
    "\n",
    "# def label_generator(gt, anchor_boxes):\n",
    "#     label = np.empty(shape=(1, anchor_boxes.shape[0]))\n",
    "#     max_iou = 0\n",
    "#     for j in range(label.shape[1]):\n",
    "#         iou = IoU(gt, anchor_boxes[j])\n",
    "#         if iou >= 0.7:\n",
    "#             label[0][j] = 1\n",
    "#         elif iou < 0.3:\n",
    "#             label[0][j] = -1\n",
    "#         else:\n",
    "#             label[0][j] = 0\n",
    "\n",
    "#         if iou > max_iou:\n",
    "#             tmp = j\n",
    "#     label[0][tmp] = 1\n",
    "#     return label.tolist()\n",
    "\n",
    "# n_jobs=2\n",
    "# parallel = Parallel(n_jobs=n_jobs)\n",
    "# ground_truths = np.array(ground_truth.iloc[:,1:])\n",
    "\n",
    "# label = parallel(\n",
    "#     delayed(label_generator)(gt=gt, anchor_boxes=anchor_boxes) \n",
    "#     for gt in tqdm(ground_truths)\n",
    "# )\n",
    "\n",
    "# label = np.array(label).reshape(-1, 72360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "comfortable-privilege",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_generator(ground_truth, anchor_boxes):\n",
    "    ground_truth = np.array(ground_truth.iloc[:,1:])\n",
    "    label = np.empty(shape=(len(ground_truth), anchor_boxes.shape[0]))\n",
    "    for i in tqdm(range(label.shape[0])):\n",
    "        gt = ground_truth[i]\n",
    "        max_iou = 0\n",
    "        for j in range(label.shape[1]):\n",
    "            iou = IoU(gt, anchor_boxes[j])\n",
    "            if iou >= 0.7:\n",
    "                label[i][j] = 1\n",
    "            elif iou < 0.3:\n",
    "                label[i][j] = 0\n",
    "            else:\n",
    "                label[i][j] = -1\n",
    "                \n",
    "            if iou > max_iou:\n",
    "                tmp = i, j\n",
    "                \n",
    "        label[tmp[0]][tmp[1]] = 1\n",
    "    return label    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dense-juice",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:40<00:00,  1.23it/s]\n"
     ]
    }
   ],
   "source": [
    "labels = label_generator(ground_truth, anchor_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "tutorial-exclusive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1., -1., -1., ..., -1., -1., -1.],\n",
       "       ...,\n",
       "       [-1., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1., -1., -1., ..., -1., -1., -1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-auditor",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "### Region Proposal Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "consistent-nylon",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RPN(tf.keras.layers.Layer):\n",
    "    def __init__(self, k=9, **kwargs):\n",
    "        super(RPN, self).__init__(**kwargs)\n",
    "        self.k = k\n",
    "        self.window = tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=1, padding='same')\n",
    "        self.bounding = tf.keras.layers.Conv2D(filters=self.k*4, kernel_size=1, activation='sigmoid')\n",
    "        self.cls = tf.keras.layers.Conv2D(filters=self.k, kernel_size=1, activation='relu')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        intermediate = self.window(inputs)\n",
    "        cls_ = self.cls(intermediate)\n",
    "        bounding_ = self.bounding(intermediate)\n",
    "        return cls_, bounding_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "handy-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpn = RPN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "serial-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls, bounding = rpn(feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fourth-night",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 33, 60, 18])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "arabic-peeing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 33, 60, 36])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "hispanic-senior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17820"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "33* 60 * 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-cancellation",
   "metadata": {},
   "source": [
    "## Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-terminology",
   "metadata": {},
   "source": [
    "### RoI pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "union-thong",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow.keras.backend' from 'C:\\\\Users\\\\kwon\\\\anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\keras\\\\backend\\\\__init__.py'>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "powerful-amazon",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class RoIPooling(tf.keras.layers.Layer):\n",
    "    def __init__(self, pool_size, num_rois, **kwargs):\n",
    "        super(RoIPooling, self).__init__(**kwargs)\n",
    "        self.pool_size = pool_size\n",
    "        self.num_rois = num_rois\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.nb_channels = input_shape[0][3]   \n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.num_rois, self.pool_size, self.pool_size, self.nb_channels)\n",
    "\n",
    "    def call(self, x):\n",
    "        \n",
    "        assert(len(x) == 2)\n",
    "\n",
    "        # x[0] is image with shape (rows, cols, channels)\n",
    "        img = x[0]\n",
    "\n",
    "        # x[1] is roi with shape (num_rois,4) with ordering (x,y,w,h)\n",
    "        rois = x[1]\n",
    "\n",
    "        input_shape = tf.shape(img)\n",
    "\n",
    "        outputs = []\n",
    "        for roi_idx in range(self.num_rois):\n",
    "\n",
    "            x = rois[0, roi_idx, 0]\n",
    "            y = rois[0, roi_idx, 1]\n",
    "            w = rois[0, roi_idx, 2]\n",
    "            h = rois[0, roi_idx, 3]\n",
    "\n",
    "            x = tf.keras.backend.cast(x, 'int32')\n",
    "            y = tf.keras.backend.cast(y, 'int32')\n",
    "            w = tf.keras.backend.cast(w, 'int32')\n",
    "            h = tf.keras.backend.cast(h, 'int32')\n",
    "\n",
    "            # Resized roi of the image to pooling size (7x7)\n",
    "            rs = tf.image.resize(img[:, y:y+h, x:x+w, :], (self.pool_size, self.pool_size))\n",
    "            outputs.append(rs)\n",
    "                \n",
    "\n",
    "        final_output = tf.keras.backend.concatenate(outputs, axis=0)\n",
    "\n",
    "        # Reshape to (1, num_rois, pool_size, pool_size, nb_channels)\n",
    "        final_output = tf.keras.backend.reshape(final_output, (1, self.num_rois, self.pool_size, self.pool_size, self.nb_channels))\n",
    "\n",
    "        # permute_dimensions is similar to transpose\n",
    "        final_output = tf.keras.backend.permute_dimensions(final_output, (0, 1, 2, 3, 4))\n",
    "\n",
    "        return final_output\n",
    "    \n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'pool_size': self.pool_size,\n",
    "                  'num_rois': self.num_rois}\n",
    "        base_config = super(RoiPoolingConv, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "solved-music",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROIPoolingLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, h, w, **kwargs):\n",
    "        super(RoIPooling, self).__init__(**kwargs)\n",
    "        self.h = h\n",
    "        self.w = w\n",
    "        \n",
    "    @staticmethod\n",
    "    def _pool_rois(feature_map, rois, pooled_height, pooled_width):\n",
    "        def curried_pool_roi(roi):\n",
    "            return ROIPoolingLayer._pool_roi(feature_map, roi,\n",
    "                                             pooled_height, pooled_width)\n",
    "\n",
    "        pooled_areas = tf.map_fn(curried_pool_roi, rois, dtype=tf.float32)\n",
    "        return pooled_areas\n",
    "\n",
    "    @staticmethod\n",
    "    def _pool_roi(feature_map, roi, pooled_height, pooled_width):\n",
    "\n",
    "        feature_map_height = int(feature_map.shape[0])\n",
    "        feature_map_width = int(feature_map.shape[1])\n",
    "\n",
    "        h_start = tf.cast(feature_map_height * roi[0], 'int32')\n",
    "        w_start = tf.cast(feature_map_width * roi[1], 'int32')\n",
    "        h_end = tf.cast(feature_map_height * roi[2], 'int32')\n",
    "        w_end = tf.cast(feature_map_width * roi[3], 'int32')\n",
    "\n",
    "        region = feature_map[h_start:h_end, w_start:w_end, :]\n",
    "\n",
    "        region_height = h_end - h_start\n",
    "        region_width = w_end - w_start\n",
    "        h_step = tf.cast(region_height / pooled_height, 'int32')\n",
    "        w_step = tf.cast(region_width / pooled_width, 'int32')\n",
    "\n",
    "        areas = [[(\n",
    "            i*h_step,\n",
    "            j*w_step,\n",
    "            (i+1)*h_step if i+1 < pooled_height else region_height,\n",
    "            (j+1)*w_step if j+1 < pooled_width else region_width\n",
    "        )\n",
    "            for j in range(pooled_width)]\n",
    "            for i in range(pooled_height)]\n",
    "\n",
    "        def pool_area(x):\n",
    "            return tf.math.reduce_max(region[x[0]:x[2], x[1]:x[3], :], axis=[0, 1])\n",
    "\n",
    "        pooled_features = tf.stack([[pool_area(x) for x in row] for row in areas])\n",
    "        return pooled_features\n",
    "        \n",
    "    def call(self, x):\n",
    "        def curried_pool_rois(x):\n",
    "            return ROIPoolingLayer._pool_rois(x[0], x[1],\n",
    "                                              self.pooled_height,\n",
    "                                              self.pooled_width)\n",
    "\n",
    "        pooled_areas = tf.map_fn(curried_pool_rois, x, dtype=tf.float32)\n",
    "        return pooled_areas\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        feature_map_shape, rois_shape = input_shape\n",
    "        assert feature_map_shape[0] == rois_shape[0]\n",
    "        batch_size = feature_map_shape[0]\n",
    "        n_rois = rois_shape[1]\n",
    "        n_channels = feature_map_shape[3]\n",
    "        return (batch_size, n_rois, self.pooled_height,\n",
    "                self.pooled_width, n_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-wiring",
   "metadata": {},
   "source": [
    "### Non-Maximum Suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "homeless-monster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=float64, numpy=array([[ 930.1 , 1169.9 ,  302.95,  854.05]])>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = [1.8, 0.4, 2, 5]\n",
    "selected_indices = tf.image.non_max_suppression(ground_truths[:4], scores, max_output_size=100)\n",
    "tf.gather(ground_truths[:4], selected_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "accompanied-costume",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 930, 1169,  302,  854],\n",
       "       [ 975, 1171,  292,  867],\n",
       "       [ 947, 1142,  289,  864],\n",
       "       [ 965, 1152,  297,  866]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Non_Maximum_Suppression(ground_truths[:4], scores, iou_threshold=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-newcastle",
   "metadata": {},
   "source": [
    "### RoI Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-racing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-naples",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "baking-magnet",
   "metadata": {},
   "source": [
    "###  Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-crawford",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs : RoI pooled fixed size feature map\n",
    "# output : \n",
    "\n",
    "class Classifie(tf.keras.layers.Layer):\n",
    "    def __init__(self, base_layers, input_rois, **kwargs):\n",
    "        super(Classifie, self).__init__(**kwargs)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense()\n",
    "        self.dense2 = tf.kersa.layers.Dense()\n",
    "        \n",
    "        self.dense3 = tf.keras.layers.Dense()\n",
    "        \n",
    "        self.dense4a = tf.keras.layers.Dense(activation='softmax')\n",
    "        self.dense4b = tf.keras.layers.Dense()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.flatten(inputs)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        softmax = self.dense4a(x)\n",
    "        bbox_regressor = self.dense4b(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-algorithm",
   "metadata": {},
   "source": [
    "## Faster R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-programmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Faster_RCNN(tf.kersa.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Faster_RCNN, self).__init__(*kwargs)\n",
    "        self.rpn = RPN()\n",
    "        self.rois = RoI()\n",
    "        self.detector = Detector()\n",
    "\n",
    "    def compile(self, optimizer, ...):\n",
    "        super(Faster_RCNN, self).compile()\n",
    "        self.optimizer = optimizer\n",
    "        ...\n",
    "        \n",
    "        self.rpn_loss_tracker = tf.keras.metrics.Mean(name='rpn_loss')\n",
    "        self.detector_loss_tracker = tf.keras.metrics.Mean(name='detector_loss')\n",
    "        \n",
    "    def RPN_Loss(self, z):\n",
    "        pass\n",
    "\n",
    "    def Detector_Loss(self, x, z):\n",
    "        pass\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        batch_size = tf.shape(data)[0]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            generated_image = self.Generating(num=batch_size)\n",
    "            discriminator_loss = self.Discriminator_Loss(data, generated_image)\n",
    "        grad = tape.gradient(discriminator_loss, self.discriminator.trainable_weights)\n",
    "        self.discriminator_optimizer.apply_gradients(zip(grad, self.discriminator.trainable_weights))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            generated_image = self.Generating(num=batch_size)\n",
    "            generator_loss = self.Generator_Loss(generated_image)\n",
    "        grad = tape.gradient(generator_loss, self.generator.trainable_weights)\n",
    "        self.generator_optimizer.apply_gradients(zip(grad, self.generator.trainable_weights))\n",
    "\n",
    "        self.generator_loss_tracker.update_state(generator_loss)\n",
    "        self.discriminator_loss_tracker.update_state(discriminator_loss)\n",
    "\n",
    "        return {\n",
    "            'discriminator_loss': self.discriminator_loss_tracker.result(),\n",
    "            'generator_loss' : self.generator_loss_tracker.result()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-absence",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-margin",
   "metadata": {},
   "source": [
    "### classification Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-phrase",
   "metadata": {},
   "source": [
    "### bounding box regression Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "heavy-funeral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tqdm.std.tqdm"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqdm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "240.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "385px",
    "left": "869px",
    "right": "20px",
    "top": "98px",
    "width": "478px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
