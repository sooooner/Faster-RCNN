{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "identified-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "reliable-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./res/train_df.csv')\n",
    "image = cv2.imread('./res/train_imgs/001-1-1-01-Z17_A-0000001.jpg', cv2.COLOR_BGR2RGB)\n",
    "inputs = tf.expand_dims(image, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "about-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(image)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "brave-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x_min'] = df.iloc[:, 1:49:2].apply(lambda x: int(min(x)), axis=1)\n",
    "df['x_max'] = df.iloc[:, 1:49:2].apply(lambda x: int(max(x)), axis=1)\n",
    "df['y_min'] = df.iloc[:, 2:49:2].apply(lambda x: int(min(x)), axis=1)\n",
    "df['y_max'] = df.iloc[:, 2:49:2].apply(lambda x: int(max(x)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "ordered-movie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-albuquerque",
   "metadata": {},
   "source": [
    "# Faster R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-chaos",
   "metadata": {},
   "source": [
    "## backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-thesaurus",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "ruled-ratio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet = tf.keras.applications.resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-annex",
   "metadata": {},
   "source": [
    "### VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "protective-bubble",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base(img_size, model='vgg'):\n",
    "    if model=='vgg':\n",
    "        base_model = tf.keras.applications.VGG16(include_top=False, input_shape=img_size)\n",
    "    elif model == 'resnet':\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception('vgg, resnet')\n",
    "        \n",
    "    base_model = tf.keras.applications.VGG16(include_top=False, weights='imagenet', input_shape=img_size)\n",
    "    feature_extractor = base_model.get_layer(\"block5_conv3\")\n",
    "    base_model = tf.keras.models.Model(inputs=base_model.input, outputs=feature_extractor.output)\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "cardiovascular-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = get_base(image.shape, model='vgg')\n",
    "\n",
    "# inputs = tf.expand_dims(image, 0)\n",
    "\n",
    "# output_map = base_model(inputs)\n",
    "# imgArray = output_map.numpy().squeeze(0)\n",
    "# # output_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-conspiracy",
   "metadata": {},
   "source": [
    "## Region Proposal Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-distributor",
   "metadata": {},
   "source": [
    "### Image resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "amber-canvas",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "adjusted-hungarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "432.0"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1080 * 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "sunrise-scout",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768.0"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1920 * 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "chubby-afghanistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ry = 600/1080\n",
    "# Rx = 1072/1920\n",
    "\n",
    "# Ry = 600/1080\n",
    "# Rx = 600/1920\n",
    "\n",
    "# Ry = size[0]/1080\n",
    "# Rx = size[0]/1920\n",
    "\n",
    "Ry = 0.4\n",
    "Rx = 0.4\n",
    "size = (432, 768)\n",
    "\n",
    "df_new.iloc[:, 1:49:2] = df_new.iloc[:, 1:49:2] * Rx\n",
    "df_new.iloc[:, 2:49:2] = df_new.iloc[:, 2:49:2] * Ry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "unauthorized-caribbean",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['x_min'] = df_new.iloc[:, 1:49:2].apply(lambda x: int(min(x)), axis=1)\n",
    "df_new['x_max'] = df_new.iloc[:, 1:49:2].apply(lambda x: int(max(x)), axis=1)\n",
    "df_new['y_min'] = df_new.iloc[:, 2:49:2].apply(lambda x: int(min(x)), axis=1)\n",
    "df_new['y_max'] = df_new.iloc[:, 2:49:2].apply(lambda x: int(max(x)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "beginning-benefit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(432, 768, 3)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = np.copy(cv2.resize(image, size[::-1]))\n",
    "inputs = tf.expand_dims(image, 0)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-exhibit",
   "metadata": {},
   "source": [
    "### Ground Truth Generating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "exterior-intelligence",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = df_new.iloc[:,:1].copy() \n",
    "ground_truth['x_min'] = df_new['x_min'] - (df_new['x_max'] - df_new['x_min'])*.065\n",
    "ground_truth['x_max'] = df_new['x_max'] + (df_new['x_max'] - df_new['x_min'])*.065\n",
    "ground_truth['y_min'] = df_new['y_min'] - (df_new['y_max'] - df_new['y_min'])*.065\n",
    "ground_truth['y_max'] = df_new['y_max'] + (df_new['y_max'] - df_new['y_min'])*.065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "meaning-toner",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth['w'] = ground_truth['x_max'] - ground_truth['x_min']\n",
    "ground_truth['h'] = ground_truth['y_max'] - ground_truth['y_min']\n",
    "ground_truth['x'] = ground_truth['w']/2 + ground_truth['x_min']\n",
    "ground_truth['y'] = ground_truth['h']/2 + ground_truth['y_min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "removed-hughes",
   "metadata": {},
   "outputs": [],
   "source": [
    "GT = np.array(ground_truth[['x', 'y', 'w', 'h']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "acquired-biology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78.40278438933144, 160.93931523544822, 278.6612992505418)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(np.sqrt(GT[:, 2] * GT[:, 3])), np.mean(np.sqrt(GT[:, 2] * GT[:, 3])), max(np.sqrt(GT[:, 2] * GT[:, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "identified-system",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97.5204133751619, 224.35821709573455)"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.sqrt(GT[:, 2] * GT[:, 3])) - 2*np.std(np.sqrt(GT[:, 2] * GT[:, 3])), np.mean(np.sqrt(GT[:, 2] * GT[:, 3])) + 2*np.std(np.sqrt(GT[:, 2] * GT[:, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "deadly-ultimate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min : 78\n",
      "mean - 3 std : 65\n",
      "mean : 160\n",
      "mean + 3 std : 256\n",
      "max : 278\n"
     ]
    }
   ],
   "source": [
    "sigma = 3\n",
    "print(f'min : {int(np.min(np.sqrt(GT[:, 2] * GT[:, 3])))}')\n",
    "print(f'mean - {sigma} std : {int(np.mean(np.sqrt(GT[:, 2] * GT[:, 3])) - sigma*np.std(np.sqrt(GT[:, 2] * GT[:, 3])))}')\n",
    "print(f'mean : {int(np.mean(np.sqrt(GT[:, 2] * GT[:, 3])))}')\n",
    "print(f'mean + {sigma} std : {int(np.mean(np.sqrt(GT[:, 2] * GT[:, 3])) + sigma*np.std(np.sqrt(GT[:, 2] * GT[:, 3])))}')\n",
    "print(f'max : {int(np.max(np.sqrt(GT[:, 2] * GT[:, 3])))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "assigned-aging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비율의 평균 : 2.6544662108614125\n",
      "w, h 에 곱해줄 비율 : w = 0.7071067811865475, h = 1.8708286933869707\n",
      "적용한 비율 : h/w = 2.6457513110645907\n"
     ]
    }
   ],
   "source": [
    "# h가 w보다 큰 경우 h/w 비율의 평균\n",
    "GT_h = GT[(GT[:, 2]/GT[:, 3] < 1)]\n",
    "print('비율의 평균 :', np.mean(GT_h[:, 3] / GT_h[:, 2]))\n",
    "print(f'w, h 에 곱해줄 비율 : w = {1/np.sqrt(2)}, h = {np.sqrt(3.5)}')\n",
    "print(f'적용한 비율 : h/w = {np.sqrt(3.5) / (1/np.sqrt(2))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "indirect-hobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비율의 평균 : 2.454610664879193\n",
      "w, h 에 곱해줄 비율 : w = 1.7320508075688772, h = 0.7071067811865475\n",
      "적용한 비율 : w/h = 2.4494897427831783\n"
     ]
    }
   ],
   "source": [
    "# w가 h보다 큰 경우 w/h 비율의 평균\n",
    "GT_w = GT[(GT[:, 2]/GT[:, 3] > 1)]\n",
    "print('비율의 평균 :', np.mean(GT_w[:, 2] / GT_w[:, 3]))\n",
    "print(f'w, h 에 곱해줄 비율 : w = {np.sqrt(3)}, h = {1/np.sqrt(2)}')\n",
    "print(f'적용한 비율 : w/h = {np.sqrt(3) / (1/np.sqrt(2))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-invention",
   "metadata": {},
   "source": [
    "### Anchor boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "married-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anchor_box_generator(x, y):\n",
    "    scales = [97, 160, 256]\n",
    "#     ratio = [(1/np.sqrt(2), np.sqrt(2)), (1, 1), (np.sqrt(2), 1/np.sqrt(2))]\n",
    "    ratio = [(1/np.sqrt(2), np.sqrt(3.5)), (1, 1), (np.sqrt(3), 1/np.sqrt(2))]\n",
    "    anchor_boxes = []\n",
    "    for scale in scales:\n",
    "        for w, h  in ratio:\n",
    "            w *= scale\n",
    "            h *= scale\n",
    "            \n",
    "            anchor_boxes.append([x, y, w, h])\n",
    "    return anchor_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "phantom-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def anchor_box_generator(x, y):\n",
    "# #     ratio = [(1/np.sqrt(2), np.sqrt(2)), (1, 1), (np.sqrt(2), 1/np.sqrt(2))]\n",
    "# #     scales = [64, 128, 256, 512]\n",
    "#     scales = [(188, 111), (113, 114), (70, 92), (416, 229), (261, 284), (174, 332), (768, 437), (499, 501), (355, 715)]\n",
    "#     anchor_boxes = []\n",
    "#     for w, h  in scales:\n",
    "#           anchor_boxes.append([x, y, w, h])\n",
    "#     return anchor_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "attempted-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Anchor_Boxes(img_shape, model='vgg'):\n",
    "    '''\n",
    "    input\n",
    "    img_shape : image shape\n",
    "    output \n",
    "    numpy array shape (w * h * 9, 4)\n",
    "    '''\n",
    "    if model == 'vgg':\n",
    "        ratio = 2**4\n",
    "        \n",
    "    w=image.shape[1]//ratio\n",
    "    h=image.shape[0]//ratio\n",
    "    \n",
    "    anchor_boxes = []\n",
    "    for x in range(image.shape[1]//w//2, image.shape[1], image.shape[1]//w):\n",
    "        for y in range(image.shape[0]//h//2, image.shape[0], image.shape[0]//h):\n",
    "            anchor_boxes.append(anchor_box_generator(x, y))\n",
    "    return np.array(anchor_boxes).reshape(-1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "dated-bristol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11664"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_boxes = Anchor_Boxes(img_shape=image.shape, model='vgg')\n",
    "len(anchor_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "champion-converter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ratio = 2**4\n",
    "\n",
    "w=image.shape[1]//ratio\n",
    "h=image.shape[0]//ratio\n",
    "img_ = np.copy(image)\n",
    "\n",
    "ground_truth_row = ground_truth.iloc[0]\n",
    "x1 = int(ground_truth_row['x_min'])\n",
    "x2 = int(ground_truth_row['x_max'])\n",
    "y1 = int(ground_truth_row['y_min'])\n",
    "y2 = int(ground_truth_row['y_max'])\n",
    "cv2.rectangle(img_, (x1, y1), (x2, y2), (0, 0, 0), thickness=2)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for x in range(img_.shape[1]//w//2, img_.shape[1], img_.shape[1]//w):\n",
    "    for y in range(img_.shape[0]//h//2, img_.shape[0], img_.shape[0]//h):\n",
    "            cv2.circle(img_, (x, y), radius=1, color=(255, 0, 0), thickness=2)\n",
    "            \n",
    "# plt.imshow(img_)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-estonia",
   "metadata": {},
   "source": [
    "### IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "useful-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def anchor_to_coordinate(boxeses):    \n",
    "#     x1 = boxes[:, 0] - boxes[:, 2]/2\n",
    "#     x2 = boxes[:, 0] + boxes[:, 2]/2\n",
    "#     y1 = boxes[:, 1] - boxes[:, 3]/2\n",
    "#     y2 = boxes[:, 1] + boxes[:, 3]/2\n",
    "#     return np.stack([x1, x2, y1, y2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "perceived-fighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def coordinate_to_anxhor(boxeses):\n",
    "#     w = boxes[:, 1] - boxes[:, 0]\n",
    "#     h = boxes[:, 3] - boxes[:, 2]\n",
    "#     x = boxes[:, 0] + w/2\n",
    "#     y = boxes[:, 2] + h/2\n",
    "#     return np.stack([x, y, w, h], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "silent-litigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def IoU(box1, box2):\n",
    "#     '''\n",
    "#     anchor ver\n",
    "#     '''\n",
    "#     box1_area = box1[2] * box1[3]\n",
    "#     box2_area = box2[2] * box2[3]\n",
    "    \n",
    "#     x1 = max(box1[0] - box1[2]/2, box2[0] - box2[2]/2)\n",
    "#     x2 = min(box1[0] + box1[2]/2, box2[0] + box2[2]/2)\n",
    "    \n",
    "#     y1 = max(box1[1] - box1[3]/2, box2[1] - box2[3]/2)\n",
    "#     y2 = min(box1[1] + box1[3]/2, box2[1] + box2[3]/2)\n",
    "    \n",
    "#     h = max(0.0, y2 - y1 + 1)\n",
    "#     w = max(0.0, x2 - x1 + 1)\n",
    "    \n",
    "#     if (w <= 0) or (h <= 0):\n",
    "#         return 0.0\n",
    "    \n",
    "#     intersect = h * w\n",
    "#     union = box1_area + box2_area - intersect\n",
    "#     return intersect / union "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "closing-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def IoU(box1, box2):\n",
    "#     '''\n",
    "#     coordinate ver\n",
    "#     '''\n",
    "#     box1_area = (box1[1] - box1[0] + 1) * (box1[3] - box1[2] + 1)\n",
    "#     box2_area = (box2[1] - box2[0] + 1) * (box2[3] - box2[2] + 1)\n",
    "    \n",
    "#     x1 = max(box1[0], box2[0])\n",
    "#     x2 = min(box1[1], box2[1])\n",
    "    \n",
    "#     y1 = max(box1[2], box2[2])\n",
    "#     y2 = min(box1[3], box2[3])    \n",
    "    \n",
    "#     h = max(0.0, y2 - y1 + 1)\n",
    "#     w = max(0.0, x2 - x1 + 1)\n",
    "    \n",
    "#     if (w <= 0) or (h <= 0):\n",
    "#         return 0.0\n",
    "    \n",
    "#     intersect = h * w\n",
    "#     union = box1_area + box2_area - intersect\n",
    "    \n",
    "#     iou = intersect / union\n",
    "#     return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "funny-illness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(box1, anchor_boxes):\n",
    "    '''\n",
    "    anchor ver\n",
    "    inputs\n",
    "    box1 : ground truth box\n",
    "    anchor_boxes : anchor boxes\n",
    "    '''\n",
    "    broadcast = len(anchor_boxes)\n",
    "    \n",
    "    box1_area = box1[2] * box1[3]\n",
    "    box2_area = anchor_boxes[:,2] * anchor_boxes[:,3]\n",
    "    \n",
    "    x1 = np.max([np.broadcast_to(box1[0] - box1[2]/2, broadcast), anchor_boxes[:, 0] - anchor_boxes[:, 2]/2], axis=0)\n",
    "    x2 = np.min([np.broadcast_to(box1[0] + box1[2]/2, broadcast), anchor_boxes[:, 0] + anchor_boxes[:, 2]/2], axis=0)\n",
    "    \n",
    "    y1 = np.max([np.broadcast_to(box1[1] - box1[3]/2, broadcast), anchor_boxes[:, 1] - anchor_boxes[:, 3]/2], axis=0)\n",
    "    y2 = np.min([np.broadcast_to(box1[1] + box1[3]/2, broadcast), anchor_boxes[:, 1] + anchor_boxes[:, 3]/2], axis=0)\n",
    "    \n",
    "    h = np.max([np.broadcast_to(0.0, broadcast), y2 - y1 + 1], axis=0)\n",
    "    w = np.max([np.broadcast_to(0.0, broadcast), x2 - x1 + 1], axis=0)\n",
    "    \n",
    "    intersect = h * w\n",
    "    union = np.broadcast_to(box1_area, broadcast) + box2_area - intersect\n",
    "    return intersect / union "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "seven-texture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anchor_to_coordinate(box):    \n",
    "    x1 = box[0] - box[2]/2\n",
    "    x2 = box[0] + box[2]/2\n",
    "    y1 = box[1] - box[3]/2\n",
    "    y2 = box[1] + box[3]/2\n",
    "    return (x1, x2, y1, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "present-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_row = ground_truth.iloc[0]\n",
    "\n",
    "img_ = cv2.imread(f'./res/train_imgs/{ground_truth_row[\"image\"]}', cv2.COLOR_BGR2RGB)\n",
    "img_ = cv2.resize(img_, size[::-1])\n",
    "\n",
    "max_output_size = 5\n",
    "colors = {k: tuple(map(int, np.random.randint(0, 255, 3))) for k in range(max_output_size)}\n",
    "\n",
    "x1 = int(ground_truth_row['x_min'])\n",
    "x2 = int(ground_truth_row['x_max'])\n",
    "y1 = int(ground_truth_row['y_min'])\n",
    "y2 = int(ground_truth_row['y_max'])\n",
    "cv2.rectangle(img_, (x1, y1), (x2, y2), (255, 0, 0), thickness=2)\n",
    "\n",
    "gt = ground_truth_row[['x', 'y', 'w', 'h']]\n",
    "ious = IoU(gt, anchor_boxes)\n",
    "print(np.sum(ious>0.6))\n",
    "\n",
    "selected_indices = tf.image.non_max_suppression(anchor_boxes, ious, max_output_size=max_output_size, score_threshold=0.01)\n",
    "anchors = tf.gather(anchor_boxes, selected_indices)\n",
    "print(IoU(gt, anchors))\n",
    "print(gt)\n",
    "\n",
    "for i, anchor_box in enumerate(anchors):\n",
    "    anchor_box = anchor_to_coordinate(anchor_box.numpy())\n",
    "    cv2.rectangle(\n",
    "        img_, \n",
    "        (int(anchor_box[0]), int(anchor_box[2])), (int(anchor_box[1]), int(anchor_box[3])), \n",
    "        colors.get(i), \n",
    "        thickness=1\n",
    "    )\n",
    "    \n",
    "# fig, ax = plt.subplots(dpi=200)\n",
    "# ax.imshow(img_)\n",
    "# ax.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-milan",
   "metadata": {},
   "source": [
    "### Label Generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "enormous-strand",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_generator(GT, anchor_boxes):\n",
    "    cls_label = -np.ones(shape=(len(GT), anchor_boxes.shape[0]))\n",
    "    pos_iou_threshold = 0.6\n",
    "    neg_iou_threshold = 0.3\n",
    "    n_sample = 128\n",
    "    pos_ratio = 0.5\n",
    "    n_pos = int(pos_ratio * n_sample)\n",
    "    \n",
    "    for i in tqdm(range(len(GT))):\n",
    "        ious = np.apply_along_axis(IoU, 0, GT[i], anchor_boxes=anchor_boxes)\n",
    "        cls_label[i][ious >= pos_iou_threshold] = 1\n",
    "        cls_label[i][ious < neg_iou_threshold] = 0\n",
    "        cls_label[i][np.argmax(ious)] = 1\n",
    "\n",
    "        pos_index = np.where(cls_label[i] == 1)[0]\n",
    "        if len(pos_index) > n_pos:\n",
    "            disable_index = np.random.choice(\n",
    "                pos_index,\n",
    "                size = (len(pos_index) - n_pos),\n",
    "                replace=False\n",
    "            )\n",
    "            cls_label[i][disable_index] = -1\n",
    "\n",
    "        n_neg = n_sample - np.sum(cls_label[i] == 1)\n",
    "        neg_index = np.where(cls_label[i] == 0)[0]\n",
    "        if len(neg_index) > n_neg:\n",
    "            disable_index = np.random.choice(\n",
    "                neg_index, \n",
    "                size = (len(neg_index) - n_neg),             \n",
    "                replace = False\n",
    "            )\n",
    "            cls_label[i][disable_index] = -1\n",
    "            \n",
    "    reg_label = np.zeros(shape=(len(GT), anchor_boxes.shape[0], 4))\n",
    "    for i in tqdm(range(len(cls_label))):\n",
    "        reg_label[i] = anchor_boxes * np.broadcast_to(tf.cast(cls_label[i] > 0, tf.int32), (4, len(cls_label[i]))).T\n",
    "        indices = np.where(reg_label[i] != 0)[0][::4]\n",
    "        x, y, w, h = GT[i][0], GT[i][1], GT[i][2], GT[i][3]\n",
    "\n",
    "        tx = (x - reg_label[i][indices][:, 0]) / (reg_label[i][indices][:, 2])\n",
    "        ty = (y - reg_label[i][indices][:, 1]) / (reg_label[i][indices][:, 3])\n",
    "        tw = np.log(w / reg_label[i][indices][:, 2]) \n",
    "        th = np.log(h / reg_label[i][indices][:, 3]) \n",
    "        reg_label[i][indices] = np.stack([tx, ty, tw, th]).T\n",
    "        \n",
    "    return cls_label, reg_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "specified-maria",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4195/4195 [00:09<00:00, 456.72it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 4195/4195 [00:04<00:00, 948.02it/s]\n"
     ]
    }
   ],
   "source": [
    "cls_label, reg_label = label_generator(GT, anchor_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "preceding-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_inside = np.where(\n",
    "#     (anchor_boxes[:, 0] - anchor_boxes[:, 2]/2 >= 0) &\n",
    "#     (anchor_boxes[:, 0] + anchor_boxes[:, 2]/2 <= image.shape[1]) &\n",
    "#     (anchor_boxes[:, 1] - anchor_boxes[:, 3]/2 >= 0) &\n",
    "#     (anchor_boxes[:, 1] + anchor_boxes[:, 3]/2 <= image.shape[0]),\n",
    "# )[0]\n",
    "\n",
    "# valid_anchor_boxes = anchor_boxes[index_inside]\n",
    "\n",
    "# valid_anchor_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-track",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-contrast",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "built-auditor",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "### Region Proposal Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "consistent-nylon",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RPN(tf.keras.models.Model):\n",
    "    def __init__(self, img_size, anchor_boxes, k=9, backbone='vgg',**kwargs):\n",
    "        super(RPN, self).__init__(**kwargs)\n",
    "        self.backbone = backbone\n",
    "        self.img_size = img_size\n",
    "        self.anchor_boxes = anchor_boxes\n",
    "        self.k = k\n",
    "        self.base_model = get_base(self.img_size, model=self.backbone)\n",
    "        self.window = tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=1, padding='same')\n",
    "        self.bbox_reg = tf.keras.layers.Conv2D(filters=self.k*4, kernel_size=1, activation='linear')\n",
    "        self.bbox_reg_reshape = tf.keras.layers.Reshape((-1, 4), name='reg_out')\n",
    "        self.cls = tf.keras.layers.Conv2D(filters=self.k, kernel_size=1, activation='sigmoid')\n",
    "        self.cls_reshape = tf.keras.layers.Reshape((-1, 1), name='cls_out')\n",
    "\n",
    "    def compile(self, optimizer):\n",
    "        super(RPN, self).compile()\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name='loss')\n",
    "    \n",
    "    def Cls_Loss(self, y_true, y_pred):\n",
    "        indices = tf.where(tf.not_equal(y_true, tf.constant(-1.0, dtype=tf.float64)))\n",
    "        target = tf.gather_nd(y_true, indices)\n",
    "        output = tf.gather_nd(y_pred, indices)\n",
    "        return tf.losses.BinaryCrossentropy()(target, output)\n",
    "\n",
    "    def Reg_Loss(self, y_true, y_pred):\n",
    "        indices = tf.reduce_any(tf.not_equal(y_true, 0), axis=-1)\n",
    "        loss_fn = tf.losses.Huber(reduction=tf.losses.Reduction.NONE)\n",
    "        loss_for_all = loss_fn(y_true[indices], y_pred[indices])\n",
    "        loss_for_all = tf.reduce_mean(loss_for_all, axis=-1)\n",
    "        return loss_for_all\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        y_cls = y[0]\n",
    "        y_reg = y[1]\n",
    "        rpn_lambda = 10\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            cls, bbox_reg = self(x, training=True)\n",
    "            cls_loss = self.Cls_Loss(y_cls, cls)\n",
    "            reg_loss = self.Reg_Loss(y_reg, bbox_reg)\n",
    "            losses = cls_loss + rpn_lambda * reg_loss\n",
    "            \n",
    "        trainable_vars = self.trainable_variables\n",
    "        grad = tape.gradient(losses, trainable_vars)\n",
    "        self.optimizer.apply_gradients(zip(grad, trainable_vars))\n",
    "        self.loss_tracker.update_state(losses)\n",
    "        return {'rpn_loss': self.loss_tracker.result()}\n",
    "\n",
    "    def call(self, inputs):\n",
    "        feature_extractor = self.base_model(inputs)\n",
    "        intermediate = self.window(feature_extractor)\n",
    "        cls_ = self.cls(intermediate)\n",
    "        cls = self.cls_reshape(cls_)\n",
    "        bbox_reg_ = self.bbox_reg(intermediate)\n",
    "        bbox_reg = self.bbox_reg_reshape(bbox_reg_)\n",
    "        return cls, bbox_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "handy-array",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - rpn_loss: 89.9697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d30717c288>"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "rpn = RPN(img_size=image.shape, anchor_boxes=anchor_boxes, k=9, backbone='vgg')\n",
    "cls, bounding = rpn(inputs)\n",
    "\n",
    "rpn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "\n",
    "rpn.fit(\n",
    "    x=tf.expand_dims(image, 0), \n",
    "    y=(tf.expand_dims(cls_label[0], 0), tf.expand_dims(reg_label[0], 0))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "white-investigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "score, rp = rpn(tf.expand_dims(image, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "stainless-enterprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = tf.squeeze(score).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "cooperative-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = tf.squeeze(rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "decent-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = np.zeros(anchor_boxes.shape)\n",
    "\n",
    "rois[:, 0] = anchor_boxes[:, 0] + anchor_boxes[:, 2] * rp[:, 0]\n",
    "rois[:, 1] = anchor_boxes[:, 1] + anchor_boxes[:, 3] * rp[:, 1]\n",
    "rois[:, 2] = anchor_boxes[:, 2] * tf.exp(rp[:, 2])\n",
    "rois[:, 3] = anchor_boxes[:, 3] * tf.exp(rp[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "worse-simon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anchor_to_coordinate(boxes):    \n",
    "    x1 = boxes[:, 0] - boxes[:, 2]/2\n",
    "    x2 = boxes[:, 0] + boxes[:, 2]/2\n",
    "    y1 = boxes[:, 1] - boxes[:, 3]/2\n",
    "    y2 = boxes[:, 1] + boxes[:, 3]/2\n",
    "    return np.stack([x1, x2, y1, y2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "agricultural-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = anchor_to_coordinate(rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "psychological-paint",
   "metadata": {},
   "outputs": [],
   "source": [
    "rois[:, 0] = np.clip(rois[:, 0], 0, size[1])\n",
    "rois[:, 1] = np.clip(rois[:, 1], 0, size[1])\n",
    "rois[:, 2] = np.clip(rois[:, 2], 0, size[0])\n",
    "rois[:, 3] = np.clip(rois[:, 3], 0, size[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "rolled-warren",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2817,) (2817, 4) (2817,)\n"
     ]
    }
   ],
   "source": [
    "min_size = 16\n",
    "hs = rois[:, 3] - rois[:, 2]\n",
    "ws = rois[:, 1] - rois[:, 0]\n",
    "\n",
    "keep = np.where((hs >= min_size) & (ws >= min_size))[0]\n",
    "rois = rois[keep, :]\n",
    "\n",
    "scores = score[keep]\n",
    "print(keep.shape, rois.shape, scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "specific-cleaner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,) (2000, 4)\n"
     ]
    }
   ],
   "source": [
    "order = scores.ravel().argsort()[::-1]\n",
    "\n",
    "n_train_pre_nms = 2000\n",
    "order = order[:n_train_pre_nms]\n",
    "rois = rois[order, :]\n",
    "print(order.shape, rois.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-burlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 64 # number of samples from roi\n",
    "pos_ratio = 0.25 # number of positive examples out of the n_samples\n",
    "pos_iou_thresh = 0.5 # min iou of region proposal with any ground truth object to consider it as positive label\n",
    "neg_iou_thresh_hi = 0.5 # iou 0~0.5 is considered as negative (0, background)\n",
    "neg_iou_thresh_lo = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "configured-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinate_to_anxhor(boxes):\n",
    "    w = boxes[:, 1] - boxes[:, 0]\n",
    "    h = boxes[:, 3] - boxes[:, 2]\n",
    "    x = boxes[:, 0] + w/2\n",
    "    y = boxes[:, 2] + h/2\n",
    "    return np.stack([x, y, w, h], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "delayed-walker",
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = coordinate_to_anxhor(rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "academic-storm",
   "metadata": {},
   "outputs": [],
   "source": [
    "ious = IoU(GT[0], rois)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-cancellation",
   "metadata": {},
   "source": [
    "## Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-nirvana",
   "metadata": {},
   "source": [
    "### Non-Maximum Suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anchor_to_coordinate(box):    \n",
    "    x1 = box[0] - box[2]/2\n",
    "    x2 = box[0] + box[2]/2\n",
    "    y1 = box[1] - box[3]/2\n",
    "    y2 = box[1] + box[3]/2\n",
    "    return (x1, x2, y1, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_output_size = 128\n",
    "colors = {k: tuple(map(int, np.random.randint(0, 255, 3))) for k in range(max_output_size)}\n",
    "x1 = int(ground_truth_row['x_min'])\n",
    "x2 = int(ground_truth_row['x_max'])\n",
    "y1 = int(ground_truth_row['y_min'])\n",
    "y2 = int(ground_truth_row['y_max'])\n",
    "\n",
    "img_ = image.copy()\n",
    "cv2.rectangle(img_, (x1, y1), (x2, y2), (255, 0, 0), thickness=2)\n",
    "\n",
    "selected_indices = tf.image.non_max_suppression(rois, ious, max_output_size=max_output_size, score_threshold=0.01)\n",
    "anchors = tf.gather(rois, selected_indices)\n",
    "\n",
    "for i, anchor in enumerate(anchors):\n",
    "    anchor = anchor_to_coordinate(anchor.numpy())\n",
    "    cv2.rectangle(\n",
    "        img_, \n",
    "        (int(anchor[0]), int(anchor[2])), (int(anchor[1]), int(anchor[3])), \n",
    "        colors.get(i), \n",
    "        thickness=1\n",
    "    )\n",
    "\n",
    "fig, ax = plt.subplots(dpi=200)\n",
    "ax.imshow(img_)\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-institute",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-question",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "approximate-heater",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.76"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1080*1920) / (600*600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "veterinary-roman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1080*1920) / ((1080/2) * (1920/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-carrier",
   "metadata": {},
   "source": [
    "### Regional Interest Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regional_Interest_Projection(tf.keras.layers.Lyaer):\n",
    "    def __init__(self, base_layer, regional_interest, **kwargs):\n",
    "        super(Regional_Interest_Projection, self).__init__(**kwargs)\n",
    "        self.base_layer = base_layer\n",
    "        self.regional_interest = regional_interest\n",
    "        \n",
    "    def projection(self, x):\n",
    "        pass\n",
    "        \n",
    "    def call(self, anchor_box):\n",
    "        x = projection(anchor_box)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection(inputs):\n",
    "    pass\n",
    "\n",
    "def Regional_Interest_Projection(feature_map, regional_interest):\n",
    "    return projection(feature_map, regional_interest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-terminology",
   "metadata": {},
   "source": [
    "### RoI pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "powerful-amazon",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class RoIPooling(tf.keras.layers.Layer):\n",
    "    def __init__(self, pool_size, num_rois, **kwargs):\n",
    "        super(RoIPooling, self).__init__(**kwargs)\n",
    "        self.pool_size = pool_size\n",
    "        self.num_rois = num_rois\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.nb_channels = input_shape[0][3]   \n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.num_rois, self.pool_size, self.pool_size, self.nb_channels)\n",
    "\n",
    "    def call(self, x):\n",
    "        \n",
    "        assert(len(x) == 2)\n",
    "\n",
    "        # x[0] is image with shape (rows, cols, channels)\n",
    "        img = x[0]\n",
    "\n",
    "        # x[1] is roi with shape (num_rois,4) with ordering (x,y,w,h)\n",
    "        rois = x[1]\n",
    "\n",
    "        input_shape = tf.shape(img)\n",
    "\n",
    "        outputs = []\n",
    "        for roi_idx in range(self.num_rois):\n",
    "\n",
    "            x = rois[0, roi_idx, 0]\n",
    "            y = rois[0, roi_idx, 1]\n",
    "            w = rois[0, roi_idx, 2]\n",
    "            h = rois[0, roi_idx, 3]\n",
    "\n",
    "            x = tf.keras.backend.cast(x, 'int32')\n",
    "            y = tf.keras.backend.cast(y, 'int32')\n",
    "            w = tf.keras.backend.cast(w, 'int32')\n",
    "            h = tf.keras.backend.cast(h, 'int32')\n",
    "\n",
    "            # Resized roi of the image to pooling size (7x7)\n",
    "            rs = tf.image.resize(img[:, y:y+h, x:x+w, :], (self.pool_size, self.pool_size))\n",
    "            outputs.append(rs)\n",
    "                \n",
    "\n",
    "        final_output = tf.keras.backend.concatenate(outputs, axis=0)\n",
    "\n",
    "        # Reshape to (1, num_rois, pool_size, pool_size, nb_channels)\n",
    "        final_output = tf.keras.backend.reshape(final_output, (1, self.num_rois, self.pool_size, self.pool_size, self.nb_channels))\n",
    "\n",
    "        # permute_dimensions is similar to transpose\n",
    "        final_output = tf.keras.backend.permute_dimensions(final_output, (0, 1, 2, 3, 4))\n",
    "\n",
    "        return final_output\n",
    "    \n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'pool_size': self.pool_size,\n",
    "                  'num_rois': self.num_rois}\n",
    "        base_config = super(RoiPoolingConv, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "solved-music",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROIPoolingLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, h, w, **kwargs):\n",
    "        super(RoIPooling, self).__init__(**kwargs)\n",
    "        self.h = h\n",
    "        self.w = w\n",
    "        \n",
    "    @staticmethod\n",
    "    def _pool_rois(feature_map, rois, pooled_height, pooled_width):\n",
    "        def curried_pool_roi(roi):\n",
    "            return ROIPoolingLayer._pool_roi(feature_map, roi,\n",
    "                                             pooled_height, pooled_width)\n",
    "\n",
    "        pooled_areas = tf.map_fn(curried_pool_roi, rois, dtype=tf.float32)\n",
    "        return pooled_areas\n",
    "\n",
    "    @staticmethod\n",
    "    def _pool_roi(feature_map, roi, pooled_height, pooled_width):\n",
    "\n",
    "        feature_map_height = int(feature_map.shape[0])\n",
    "        feature_map_width = int(feature_map.shape[1])\n",
    "\n",
    "        h_start = tf.cast(feature_map_height * roi[0], 'int32')\n",
    "        w_start = tf.cast(feature_map_width * roi[1], 'int32')\n",
    "        h_end = tf.cast(feature_map_height * roi[2], 'int32')\n",
    "        w_end = tf.cast(feature_map_width * roi[3], 'int32')\n",
    "\n",
    "        region = feature_map[h_start:h_end, w_start:w_end, :]\n",
    "\n",
    "        region_height = h_end - h_start\n",
    "        region_width = w_end - w_start\n",
    "        h_step = tf.cast(region_height / pooled_height, 'int32')\n",
    "        w_step = tf.cast(region_width / pooled_width, 'int32')\n",
    "\n",
    "        areas = [[(\n",
    "            i*h_step,\n",
    "            j*w_step,\n",
    "            (i+1)*h_step if i+1 < pooled_height else region_height,\n",
    "            (j+1)*w_step if j+1 < pooled_width else region_width\n",
    "        )\n",
    "            for j in range(pooled_width)]\n",
    "            for i in range(pooled_height)]\n",
    "\n",
    "        def pool_area(x):\n",
    "            return tf.math.reduce_max(region[x[0]:x[2], x[1]:x[3], :], axis=[0, 1])\n",
    "\n",
    "        pooled_features = tf.stack([[pool_area(x) for x in row] for row in areas])\n",
    "        return pooled_features\n",
    "        \n",
    "    def call(self, x):\n",
    "        def curried_pool_rois(x):\n",
    "            return ROIPoolingLayer._pool_rois(x[0], x[1],\n",
    "                                              self.pooled_height,\n",
    "                                              self.pooled_width)\n",
    "\n",
    "        pooled_areas = tf.map_fn(curried_pool_rois, x, dtype=tf.float32)\n",
    "        return pooled_areas\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        feature_map_shape, rois_shape = input_shape\n",
    "        assert feature_map_shape[0] == rois_shape[0]\n",
    "        batch_size = feature_map_shape[0]\n",
    "        n_rois = rois_shape[1]\n",
    "        n_channels = feature_map_shape[3]\n",
    "        return (batch_size, n_rois, self.pooled_height,\n",
    "                self.pooled_width, n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-racing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-naples",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "baking-magnet",
   "metadata": {},
   "source": [
    "###  Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-crawford",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifie(tf.keras.layers.Layer):\n",
    "    def __init__(self, base_layers, input_rois, **kwargs):\n",
    "        super(Classifie, self).__init__(**kwargs)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense()\n",
    "        self.dense2 = tf.kersa.layers.Dense()\n",
    "        \n",
    "        self.dense3 = tf.keras.layers.Dense()\n",
    "        \n",
    "        self.dense4a = tf.keras.layers.Dense(activation='softmax')\n",
    "        self.dense4b = tf.keras.layers.Dense()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.flatten(inputs)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        softmax = self.dense4a(x)\n",
    "        bbox_regressor = self.dense4b(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-algorithm",
   "metadata": {},
   "source": [
    "## Faster R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-programmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Faster_RCNN(tf.kersa.Model):\n",
    "    def __init__(self, train_step=0, **kwargs):\n",
    "        super(Faster_RCNN, self).__init__(*kwargs)\n",
    "        self.rpn = RPN()\n",
    "        self.rois = RoI()\n",
    "        self.detector = Detector()\n",
    "        self.train_step = train_step\n",
    "\n",
    "    def compile(self, optimizer, ...):\n",
    "        super(Faster_RCNN, self).compile()\n",
    "        self.optimizer = optimizer\n",
    "        ...\n",
    "        \n",
    "        self.rpn_loss_tracker = tf.keras.metrics.Mean(name='rpn_loss')\n",
    "        self.detector_loss_tracker = tf.keras.metrics.Mean(name='detector_loss')\n",
    "        \n",
    "    def RPN_Loss(self, z):\n",
    "        pass\n",
    "\n",
    "    def Detector_Loss(self, x, z):\n",
    "        pass\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        batch_size = tf.shape(data)[0]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            generated_image = self.Generating(num=batch_size)\n",
    "            discriminator_loss = self.Discriminator_Loss(data, generated_image)\n",
    "        grad = tape.gradient(discriminator_loss, self.discriminator.trainable_weights)\n",
    "        self.discriminator_optimizer.apply_gradients(zip(grad, self.discriminator.trainable_weights))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            generated_image = self.Generating(num=batch_size)\n",
    "            generator_loss = self.Generator_Loss(generated_image)\n",
    "        grad = tape.gradient(generator_loss, self.generator.trainable_weights)\n",
    "        self.generator_optimizer.apply_gradients(zip(grad, self.generator.trainable_weights))\n",
    "\n",
    "        self.generator_loss_tracker.update_state(generator_loss)\n",
    "        self.discriminator_loss_tracker.update_state(discriminator_loss)\n",
    "\n",
    "        return {\n",
    "            'discriminator_loss': self.discriminator_loss_tracker.result(),\n",
    "            'generator_loss' : self.generator_loss_tracker.result()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-absence",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-margin",
   "metadata": {},
   "source": [
    "### classification Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-phrase",
   "metadata": {},
   "source": [
    "### bounding box regression Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "heavy-funeral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tqdm.std.tqdm"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rpn_loss_regr_fixed_num(y_true, y_pred):\n",
    "\n",
    "        # x is the difference between true value and predicted vaue\n",
    "        x = y_true[:, :, :, 4 * num_anchors:] - y_pred\n",
    "\n",
    "        # absolute value of x\n",
    "        x_abs = K.abs(x)\n",
    "\n",
    "        # If x_abs &lt;= 1.0, x_bool = 1\n",
    "        x_bool = K.cast(K.less_equal(x_abs, 1.0), tf.float32)\n",
    "\n",
    "        return lambda_rpn_regr * K.sum(\n",
    "            y_true[:, :, :, :4 * num_anchors] * (x_bool * (0.5 * x * x) + (1 - x_bool) * (x_abs - 0.5))) / K.sum(epsilon + y_true[:, :, :, :4 * num_anchors])\n",
    "\n",
    "\n",
    "def rpn_loss_regr(num_anchors):\n",
    "    \"\"\"Loss function for rpn regression\n",
    "    Args:\n",
    "        num_anchors: number of anchors (9 in here)\n",
    "    Returns:\n",
    "        Smooth L1 loss function \n",
    "                           0.5*x*x (if x_abs &lt; 1)\n",
    "                           x_abx - 0.5 (otherwise)\n",
    "    \"\"\"\n",
    "    return rpn_loss_regr_fixed_num\n",
    "  \n",
    "def rpn_loss_cls_fixed_num(y_true, y_pred):\n",
    "\n",
    "            return lambda_rpn_class * K.sum(y_true[:, :, :, :num_anchors] * K.binary_crossentropy(y_pred[:, :, :, :], y_true[:, :, :, num_anchors:])) / K.sum(epsilon + y_true[:, :, :, :num_anchors])\n",
    "\n",
    "\n",
    "def rpn_loss_cls(num_anchors):\n",
    "    \"\"\"Loss function for rpn classification\n",
    "    Args:\n",
    "        num_anchors: number of anchors (9 in here)\n",
    "        y_true[:, :, :, :9]: [0,1,0,0,0,0,0,1,0] means only the second and the eighth box is valid which contains pos or neg anchor =&gt; isValid\n",
    "        y_true[:, :, :, 9:]: [0,1,0,0,0,0,0,0,0] means the second box is pos and eighth box is negative\n",
    "    Returns:\n",
    "        lambda * sum((binary_crossentropy(isValid*y_pred,y_true))) / N\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    return rpn_loss_cls_fixed_num"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "240.188px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 363,
   "position": {
    "height": "40px",
    "left": "869px",
    "right": "20px",
    "top": "98px",
    "width": "478px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
