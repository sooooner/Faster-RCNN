{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "identified-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import *\n",
    "from utils.intersection_over_union import IoU_np, IoU_tensor\n",
    "from utils.Augmentation import *\n",
    "from utils.label_generator import *\n",
    "from utils.regional_interest_projection import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "reliable-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./res/train_df.csv')\n",
    "image = cv2.imread('./res/train_imgs/001-1-1-01-Z17_A-0000001.jpg', cv2.COLOR_BGR2RGB)\n",
    "inputs = tf.expand_dims(image, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "about-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(image)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-albuquerque",
   "metadata": {},
   "source": [
    "# Faster R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-distributor",
   "metadata": {},
   "source": [
    "### Image resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "chubby-afghanistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_resize(df, Rx, Ry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-exhibit",
   "metadata": {},
   "source": [
    "### Ground Truth Generating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = ground_truth_generator(train)\n",
    "GT = np.array(ground_truth[['x', 'y', 'w', 'h']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-invention",
   "metadata": {},
   "source": [
    "### Anchor boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "married-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [140, 160, 180, 210, 240]\n",
    "ratio = [(1/np.sqrt(3), np.sqrt(3)), (1/np.sqrt(2), np.sqrt(2)), (1, 1), (np.sqrt(2), 1/np.sqrt(2)), (np.sqrt(3), 1/np.sqrt(3))]\n",
    "anchor_boxes = Anchor_Boxes(image1.shape, scales, ratio, model='vgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "attempted-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes = anchors_to_coordinates(anchor_boxes)\n",
    "out_boundaries_indxes = (np.where(bboxes[:, 0] < 0) or np.where(bboxes[:, 2] < 0) or np.where(bboxes[:, 1] > 768) or np.where(bboxes[:, 3] > 432))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-milan",
   "metadata": {},
   "source": [
    "### Label Generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-ecuador",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traingtGenerator():\n",
    "    Rx, Ry = 0.4, 0.4\n",
    "    image_size = (1080, 1920, 3)\n",
    "    size = [int(image_size[0] * Rx), int(image_size[1] * Ry)]\n",
    "    iter_num = len(train)\n",
    "\n",
    "    for i in range(iter_num):\n",
    "        img = tf.io.read_file(train_val_dir + 'train/' + train['image'].iloc[i]) \n",
    "        img = tf.image.decode_jpeg(img, channels=3) \n",
    "        img = tf.image.resize(img, size) \n",
    "        img = img/255                         \n",
    "        target = list(train.iloc[:,1:49].iloc[i,:])\n",
    "        gt, gt_min = gt_generator(target)\n",
    "        mask = [(target[j] - gt_min[0]) / gt[2] if j % 2 == 0 else (target[j] - gt_min[1]) / gt[3] for j in range(len(target))]\n",
    "        cls_label, reg_label = label_generator(gt, anchor_boxes, out_boundaries_indxes)\n",
    "\n",
    "        yield img, (cls_label, reg_label, gt, mask)\n",
    "    \n",
    "    for i in range(iter_num):\n",
    "        img = tf.io.read_file(train_val_dir + 'train/' + train['image'].iloc[i]) \n",
    "        img = tf.image.decode_jpeg(img, channels=3) \n",
    "        img = tf.image.resize(img, size) \n",
    "        img = img/255\n",
    "        target = train.iloc[:,1:49].iloc[i,:] \n",
    "        img, target = left_right_flip(img, target)\n",
    "        gt, gt_min = gt_generator(target)\n",
    "        mask = [(target[j] - gt_min[0]) / gt[2] if j % 2 == 0 else (target[j] - gt_min[1]) / gt[3] for j in range(len(target))]\n",
    "        cls_label, reg_label = label_generator(gt, anchor_boxes, out_boundaries_indxes)\n",
    "\n",
    "        yield img, (cls_label, reg_label, gt, mask)\n",
    "\n",
    "    for i in range(iter_num):\n",
    "        img = tf.io.read_file(train_val_dir + 'train/' + train['image'].iloc[i]) \n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, size)\n",
    "        img = img/255\n",
    "        target = train.iloc[:,1:49].iloc[i,:]\n",
    "        img_list, target_list = shift_images(img, target)\n",
    "        for shifted_img, shifted_target in zip(img_list, target_list):\n",
    "            gt, gt_min = gt_generator(shifted_target)\n",
    "            mask = [(target[j] - gt_min[0]) / gt[2] if j % 2 == 0 else (target[j] - gt_min[1]) / gt[3] for j in range(len(target))]\n",
    "            cls_label, reg_label = label_generator(gt, anchor_boxes, out_boundaries_indxes)\n",
    "\n",
    "            yield shifted_img, (cls_label, reg_label, gt, mask)\n",
    "\n",
    "    for i in range(iter_num):\n",
    "        img = tf.io.read_file(train_val_dir + 'train/' + train['image'].iloc[i]) \n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, size)\n",
    "        img = img/255\n",
    "        target = train.iloc[:,1:49].iloc[i,:]\n",
    "        img_list, target_list = rotate_augmentation(img, target)\n",
    "        for rotated_img, rotated_target in zip(img_list, target_list):\n",
    "            gt, gt_min = gt_generator(rotated_target)\n",
    "            mask = [(target[j] - gt_min[0]) / gt[2] if j % 2 == 0 else (target[j] - gt_min[1]) / gt[3] for j in range(len(target))]\n",
    "            cls_label, reg_label = label_generator(gt, anchor_boxes, out_boundaries_indxes)\n",
    "\n",
    "            yield rotated_img, (cls_label, reg_label, gt, mask)\n",
    "\n",
    "    for i in range(iter_num):\n",
    "        img = tf.io.read_file(train_val_dir + 'train/' + train['image'].iloc[i]) \n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, size)\n",
    "        img = img/255\n",
    "        target = train.iloc[:,1:49].iloc[i,:]\n",
    "        gt, gt_min = gt_generator(target)\n",
    "        mask = [(target[j] - gt_min[0]) / gt[2] if j % 2 == 0 else (target[j] - gt_min[1]) / gt[3] for j in range(len(target))]\n",
    "        cls_label, reg_label = label_generator(gt, anchor_boxes, out_boundaries_indxes)\n",
    "        img_list = alter_brightness(img)\n",
    "        for altered_brightness_images in img_list:\n",
    "\n",
    "            yield altered_brightness_images, (cls_label, reg_label, gt, mask)\n",
    "\n",
    "    for i in range(iter_num):\n",
    "        img = tf.io.read_file(train_val_dir + 'train/' + train['image'].iloc[i]) \n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, size)\n",
    "        img = img/255\n",
    "        target = train.iloc[:,1:49].iloc[i,:]\n",
    "        noisy_img = add_noise(img)\n",
    "        gt, gt_min = gt_generator(target)\n",
    "        mask = [(target[j] - gt_min[0]) / gt[2] if j % 2 == 0 else (target[j] - gt_min[1]) / gt[3] for j in range(len(target))]\n",
    "        cls_label, reg_label = label_generator(gt, anchor_boxes, out_boundaries_indxes)\n",
    "\n",
    "        yield noisy_img, (cls_label, reg_label, gt, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    traingtGenerator,\n",
    "    output_signature = (\n",
    "            tf.TensorSpec(shape=(size[0], size[1], 3)),\n",
    "            (\n",
    "                tf.TensorSpec(shape=(len(anchor_boxes))),\n",
    "                tf.TensorSpec(shape=(len(anchor_boxes),4)),\n",
    "                tf.TensorSpec(shape=(4)),\n",
    "                tf.TensorSpec(shape=(48))\n",
    "            )\n",
    "        )\n",
    ").batch(batch_size).prefetch(16*4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-conspiracy",
   "metadata": {},
   "source": [
    "## Region Proposal Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "documentary-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RPN(tf.keras.models.Model):\n",
    "    def __init__(self, base_model, anchor_boxes, k=9, n_sample=32, **kwargs):\n",
    "        super(RPN, self).__init__(**kwargs)\n",
    "        self.base_model = base_model\n",
    "        self.anchor_boxes = anchor_boxes\n",
    "        self.num_of_anchor = len(self.anchor_boxes)\n",
    "        self.n_sample = n_sample\n",
    "        self.k = k\n",
    "\n",
    "        self.window = tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=1, padding='same')\n",
    "        self.bbox_reg = tf.keras.layers.Conv2D(filters=self.k*4, kernel_size=1)\n",
    "        self.bbox_reg_reshape = tf.keras.layers.Reshape((-1, 4), name='reg_out')\n",
    "        self.cls = tf.keras.layers.Conv2D(filters=self.k, kernel_size=1, activation='sigmoid')\n",
    "        self.cls_reshape = tf.keras.layers.Reshape((-1, 1), name='cls_out')\n",
    "\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name='loss')\n",
    "        self.test_loss_tracker = tf.keras.metrics.Mean(name='test_loss')\n",
    "\n",
    "    def compile(self, optimizer):\n",
    "        super(RPN, self).compile()\n",
    "        self.optimizer = optimizer\n",
    "    \n",
    "    def Cls_Loss(self, y_true, y_pred):\n",
    "        indices = tf.where(tf.not_equal(y_true, tf.constant(-1.0, dtype=tf.float32)))\n",
    "        target = tf.gather_nd(y_true, indices)\n",
    "        output = tf.gather_nd(y_pred, indices)\n",
    "        return tf.losses.BinaryCrossentropy(reduction=tf.losses.Reduction.SUM)(target, output)/self.n_sample\n",
    "\n",
    "    def Reg_Loss(self, y_true, y_pred):\n",
    "        indices = tf.reduce_any(tf.not_equal(y_true, 0), axis=-1)\n",
    "        return tf.losses.Huber(reduction=tf.losses.Reduction.SUM)(y_true[indices], y_pred[indices])/self.num_of_anchor\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        y_cls = y[0]\n",
    "        y_reg = y[1]\n",
    "        rpn_lambda = 10\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            cls, bbox_reg, _ = self(x, training=True)\n",
    "            cls_loss = self.Cls_Loss(y_cls, cls)\n",
    "            reg_loss = self.Reg_Loss(y_reg, bbox_reg)\n",
    "            losses = cls_loss + rpn_lambda * reg_loss\n",
    "            \n",
    "        trainable_vars = self.trainable_variables\n",
    "        grad = tape.gradient(losses, trainable_vars)\n",
    "        self.optimizer.apply_gradients(zip(grad, trainable_vars))\n",
    "        self.loss_tracker.update_state(losses)\n",
    "        return {'rpn_loss': self.loss_tracker.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        y_cls = y[0]\n",
    "        y_reg = y[1]\n",
    "        \n",
    "        cls, bbox_reg, _ = self(x, training=False)\n",
    "        cls_loss = self.Cls_Loss(y_cls, cls)\n",
    "        reg_loss = self.Reg_Loss(y_reg, bbox_reg)\n",
    "        losses = cls_loss + rpn_lambda * reg_loss\n",
    "\n",
    "        self.test_loss_tracker.update_state(losses)\n",
    "        return {'rpn_loss_val': self.test_loss_tracker.result()}\n",
    "\n",
    "    def bbox_regression(self, boxes):\n",
    "        tx = (boxes[:, :, 0] - self.anchor_boxes[:, 0]) / self.anchor_boxes[:, 2]\n",
    "        ty = (boxes[:, :, 1] - self.anchor_boxes[:, 1]) / self.anchor_boxes[:, 3]\n",
    "        tw = tf.math.log(tf.maximum(boxes[:, :, 2], np.finfo(np.float64).eps) / self.anchor_boxes[:, 2])\n",
    "        th = tf.math.log(tf.maximum(boxes[:, :, 3], np.finfo(np.float64).eps) / self.anchor_boxes[:, 3])\n",
    "        return tf.stack([tx, ty, tw, th], -1)\n",
    "\n",
    "    def inverse_bbox_regression(self, boxes):\n",
    "        gx = self.anchor_boxes[:, 2] * boxes[:, :, 0] + self.anchor_boxes[:, 0]\n",
    "        gy = self.anchor_boxes[:, 3] * boxes[:, :, 1] + self.anchor_boxes[:, 1]\n",
    "        gw = self.anchor_boxes[:, 2] * tf.exp(boxes[:, :, 2])\n",
    "        gh = self.anchor_boxes[:, 3] * tf.exp(boxes[:, :, 3])\n",
    "        return tf.stack([gx, gy, gw, gh], axis=-1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        feature_extractor = self.base_model(inputs)\n",
    "        intermediate = self.window(feature_extractor)\n",
    "        cls = self.cls(intermediate)\n",
    "        cls = self.cls_reshape(cls)\n",
    "        bbox_reg = self.bbox_reg(intermediate)\n",
    "        bbox_reg = self.bbox_reg_reshape(bbox_reg)\n",
    "        bbox_reg = self.bbox_regression(bbox_reg)\n",
    "        return cls, bbox_reg, feature_extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-magnet",
   "metadata": {},
   "source": [
    "##  Classifier Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "class get_candidate_layer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(get_candidate_layer, self).__init__(**kwargs)\n",
    "\n",
    "    def anchors_clip(self, boxes, size=(432, 768)):    \n",
    "        x1 = boxes[:, :, 0] - boxes[:, :, 2]/2\n",
    "        x2 = boxes[:, :, 0] + boxes[:, :, 2]/2\n",
    "        y1 = boxes[:, :, 1] - boxes[:, :, 3]/2\n",
    "        y2 = boxes[:, :, 1] + boxes[:, :, 3]/2\n",
    "        \n",
    "        x1 = tf.clip_by_value(x1, 0, size[1])\n",
    "        x2 = tf.clip_by_value(x2, 0, size[1])\n",
    "        y1 = tf.clip_by_value(y1, 0, size[0])\n",
    "        y2 = tf.clip_by_value(y2, 0, size[0])\n",
    "\n",
    "        w = x2 - x1\n",
    "        h = y2 - y1\n",
    "        x = x1 + w/2\n",
    "        y = y1 + h/2\n",
    "        return tf.stack([x, y, w, h], axis=-1)\n",
    "\n",
    "    def call(self, x):\n",
    "        scores, rps, n_train_pre_nms = x\n",
    "        rois = self.anchors_clip(rps)\n",
    "\n",
    "        oobw = tf.expand_dims(tf.cast(tf.math.greater(rois[:, :, 2], 16), tf.float32), -1)\n",
    "        oobh = tf.expand_dims(tf.cast(tf.math.greater(rois[:, :, 3], 16), tf.float32), -1)\n",
    "        scores = tf.math.multiply(scores, oobw)\n",
    "        scores = tf.math.multiply(scores, oobh)\n",
    "\n",
    "        orders = tf.argsort(scores, direction='DESCENDING', axis=1)[:, :n_train_pre_nms]\n",
    "        rois = tf.gather_nd(rois, orders, batch_dims=1)\n",
    "        scores = tf.gather_nd(scores, orders, batch_dims=1)\n",
    "        return rois, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-federation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMS(tf.keras.layers.Layer):\n",
    "    def __init__(self, iou_threshold=0.7, **kwargs):\n",
    "        self.iou_threshold = iou_threshold\n",
    "        super(NMS, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        rois, scores, max_output_size = inputs\n",
    "        selected_indices_padded = tf.image.non_max_suppression_padded(\n",
    "            rois, \n",
    "            tf.squeeze(scores), \n",
    "            max_output_size=max_output_size,\n",
    "            iou_threshold=0.7,\n",
    "            pad_to_max_output_size=True\n",
    "        )[0]\n",
    "        nms = tf.gather(rois, selected_indices_padded, batch_dims=1)\n",
    "        return nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoIpool(tf.keras.layers.Layer):\n",
    "    def __init__(self, pool_size=7, num_rois=128, batch_size=16, **kwargs):\n",
    "        self.pool_size = pool_size\n",
    "        self.num_rois = num_rois\n",
    "        self.batch_size = batch_size\n",
    "        super(RoIpool, self).__init__(**kwargs)\n",
    "\n",
    "    def cal_rois_ratio(self, nmses, size=[432, 768]):\n",
    "        x1 = (nmses[:, :, 0] - nmses[:, :, 2]/2)/size[1]\n",
    "        x2 = (nmses[:, :, 0] + nmses[:, :, 2]/2)/size[1]\n",
    "        y1 = (nmses[:, :, 1] - nmses[:, :, 3]/2)/size[0]\n",
    "        y2 = (nmses[:, :, 1] + nmses[:, :, 3]/2)/size[0]\n",
    "        return tf.stack([y1, x1, y2, x2], axis=-1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        feature_map, nmses = inputs\n",
    "        n_channel = feature_map.shape[-1]\n",
    "        nmses = self.cal_rois_ratio(nmses)\n",
    "        rois = tf.image.crop_and_resize(\n",
    "            feature_map, \n",
    "            tf.reshape(nmses, (-1, 4)), \n",
    "            box_indices=[i for i in range(self.batch_size) for _ in range(self.num_rois)], \n",
    "            crop_size=[self.pool_size, self.pool_size]\n",
    "        )\n",
    "        return tf.reshape(rois, shape=(self.batch_size, self.num_rois, self.pool_size, self.pool_size, n_channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(tf.keras.models.Model):\n",
    "    def __init__(self, classifier_lambda=1, **kwargs):\n",
    "        super(Classifier, self).__init__(**kwargs)\n",
    "        self.classifier_lambda = classifier_lambda\n",
    "\n",
    "        self.conv = tf.keras.layers.Conv2D(2048, 7, 7, name='cls_conv')\n",
    "        self.flatten = tf.keras.layers.Flatten(name='cls_flatten')\n",
    "        self.dense = tf.keras.layers.Dense(2048, name='cls_dense')\n",
    "        self.cls = tf.keras.layers.Dense(1, activation='sigmoid', name='cls_out')\n",
    "        self.bbox_reg = tf.keras.layers.Dense(4, name='bbox_out')\n",
    "\n",
    "        self.deconv = tf.keras.layers.Conv2DTranspose(filters=256, kernel_size=(2, 2), strides=2)\n",
    "        self.bn = tf.keras.layers.BatchNormalization()\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "        \n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=80, kernel_size=1)\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.relu1 = tf.keras.layers.ReLU()\n",
    "\n",
    "        self.conv2 = tf.keras.layers.Conv2D(80, 14, 14)\n",
    "        self.flatten2 = tf.keras.layers.Flatten()\n",
    "        self.mask_out = tf.keras.layers.Dense(48, activation='sigmoid')\n",
    "\n",
    "    def compile(self, optimizer):\n",
    "        super(Classifier, self).compile()\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name='loss')\n",
    "        self.test_loss_tracker = tf.keras.metrics.Mean(name='test_loss')\n",
    "    \n",
    "    def Cls_Loss(self, y_true, y_pred):\n",
    "        return tf.losses.BinaryCrossentropy()(y_true, y_pred)\n",
    "\n",
    "    def Reg_Loss(self, y_true, y_pred, indices):\n",
    "        return tf.losses.Huber()(y_true[indices], y_pred[indices])\n",
    "\n",
    "    def Mask_Loss(self, y_true, y_pred, indices):\n",
    "        y_true = tf.reshape(tf.tile(y_true, [1, indices.shape[1]]), (-1, indices.shape[1], 48))\n",
    "        return tf.keras.losses.MSE(y_true[indices], y_pred[indices])\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        y_cls = y[0]\n",
    "        y_reg = y[1]\n",
    "        y_mask = y[2]\n",
    "        indices = tf.not_equal(y_cls, 0)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            cls, bbox_reg, mask, _ = self(x)\n",
    "            cls_loss = self.Cls_Loss(y_cls, cls)\n",
    "            reg_loss = self.Reg_Loss(y_reg, bbox_reg, indices)\n",
    "            mask_loss = self.Mask_Loss(y_mask, mask, indices)\n",
    "            losses = cls_loss + reg_loss + mask_loss\n",
    "            \n",
    "        trainable_vars = self.trainable_variables\n",
    "        grad = tape.gradient(losses, trainable_vars)\n",
    "        self.optimizer.apply_gradients(zip(grad, trainable_vars))\n",
    "        self.loss_tracker.update_state(losses)\n",
    "        return {'classifier_loss': self.loss_tracker.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        y_cls = y[0]\n",
    "        y_reg = y[1]\n",
    "        y_mask = y[2]\n",
    "        indices = tf.not_equal(y_cls, 0)\n",
    "\n",
    "        cls, bbox_reg, mask, _ = self(x, training=False)\n",
    "        cls_loss = self.Cls_Loss(y_cls, cls)\n",
    "        reg_loss = self.Reg_Loss(y_reg, bbox_reg, indices)\n",
    "        mask_loss = self.Mask_Loss(y_mask, mask, indices)\n",
    "        losses = cls_loss + reg_loss + mask_loss\n",
    "\n",
    "        self.test_loss_tracker.update_state(losses)\n",
    "        return {'classifier_loss_val': self.test_loss_tracker.result()}\n",
    "\n",
    "    def bbox_regression(self, bbox, nmses):\n",
    "        tx = (bbox[:, :, 0] - nmses[:, :, 0]) / nmses[:, :, 2]\n",
    "        ty = (bbox[:, :, 1] - nmses[:, :, 1]) / nmses[:, :, 3]\n",
    "        tw = tf.math.log(tf.maximum(bbox[:, :, 2], np.finfo(np.float64).eps) / nmses[:, :, 2])\n",
    "        th = tf.math.log(tf.maximum(bbox[:, :, 3], np.finfo(np.float64).eps) / nmses[:, :, 3])\n",
    "        return tf.stack([tx, ty, tw, th], -1)\n",
    "\n",
    "    @staticmethod\n",
    "    def inverse_bbox_regression(bbox, nmses):\n",
    "        gx = nmses[:, :, 2] * bbox[:, :, 0] + nmses[:, :, 0]\n",
    "        gy = nmses[:, :, 3] * bbox[:, :, 1] + nmses[:, :, 1]\n",
    "        gw = nmses[:, :, 2] * tf.exp(bbox[:, :, 2])\n",
    "        gh = nmses[:, :, 3] * tf.exp(bbox[:, :, 3])\n",
    "        return tf.stack([gx, gy, gw, gh], -1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        rois, nms = inputs\n",
    "\n",
    "        x = tf.keras.layers.TimeDistributed(self.deconv)(rois)\n",
    "        x = tf.keras.layers.TimeDistributed(self.bn)(x)\n",
    "        x = tf.keras.layers.TimeDistributed(self.relu)(x) \n",
    "\n",
    "        x = tf.keras.layers.TimeDistributed(self.conv1)(x)\n",
    "        x = tf.keras.layers.TimeDistributed(self.bn1)(x)\n",
    "        x = tf.keras.layers.TimeDistributed(self.relu1)(x) \n",
    "\n",
    "        x = tf.keras.layers.TimeDistributed(self.conv2)(x)\n",
    "        x = tf.keras.layers.TimeDistributed(self.flatten2)(x) \n",
    "        mask = tf.keras.layers.TimeDistributed(self.mask_out)(x)\n",
    "\n",
    "        x = tf.keras.layers.TimeDistributed(self.conv)(rois)\n",
    "        x = tf.keras.layers.TimeDistributed(self.flatten)(x)\n",
    "        feature_vector = tf.keras.layers.TimeDistributed(self.dense)(x)\n",
    "        clss = tf.keras.layers.TimeDistributed(self.cls)(feature_vector)\n",
    "        bbox = tf.keras.layers.TimeDistributed(self.bbox_reg)(feature_vector)\n",
    "        bbox_reg = self.bbox_regression(bbox, nms)\n",
    "\n",
    "        return clss, bbox_reg, mask, nms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-algorithm",
   "metadata": {},
   "source": [
    "## Faster R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Faster_RCNN(tf.keras.models.Model):\n",
    "    def __init__(self, img_size, anchor_boxes, k, n_sample, backbone, rpn_lambda, pool_size, num_rois, batch_size, classifier_lambda, **kwargs):\n",
    "        super(Faster_RCNN, self).__init__(*kwargs)\n",
    "        self.img_size = img_size\n",
    "        self.anchor_boxes = anchor_boxes\n",
    "        self.k = k\n",
    "        self.n_sample = n_sample\n",
    "        self.backbone = backbone\n",
    "        self.rpn_lambda = rpn_lambda\n",
    "        self.pool_size = pool_size\n",
    "        self.num_rois = num_rois\n",
    "        self.batch_size = batch_size\n",
    "        self.classifier_lambda = classifier_lambda\n",
    "        self.n_train_pre_nms = 12000\n",
    "        self.n_train_post_nms = 2000\n",
    "        self.n_test_pre_nms = 6000\n",
    "        self.n_test_post_nms = 128\n",
    "        self.iou_threshold = 0.7\n",
    "\n",
    "        self.rpn = RPN(img_size= self.img_size, anchor_boxes=self.anchor_boxes, k=self.k, n_sample=self.n_sample, backbone=self.backbone, rpn_lambda=self.rpn_lambda, name='rpn')\n",
    "        self.get_candidate = get_candidate_layer(name='get_candidate')\n",
    "        self.get_nms = NMS(iou_threshold=self.iou_threshold, name='get_nms')\n",
    "        self.roipool = RoIpool(pool_size=self.pool_size, num_rois=self.num_rois, batch_size=self.batch_size, name='roipool')\n",
    "        self.classifier = Classifier(classifier_lambda=self.classifier_lambda, name='classifier')\n",
    "        self.train_stage = None\n",
    "\n",
    "    def compile(self, rpn_optimizer, classifier_optimizer):\n",
    "        super(Faster_RCNN, self).compile()\n",
    "        self.rpn.compile(optimizer=rpn_optimizer)\n",
    "        self.classifier.compile(optimizer=classifier_optimizer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        scores, rps, feature_map = self.rpn(inputs)\n",
    "        rps = self.rpn.inverse_bbox_regression(rps)\n",
    "        candidate_area, scores = self.get_candidate((scores, rps, self.n_test_pre_nms))\n",
    "        nms = self.get_nms((candidate_area, scores, self.n_test_post_nms))\n",
    "        rois = self.roipool((feature_map, nms))\n",
    "        cls, bbox_reg, mask, nms = self.classifier((rois, nms))\n",
    "        predict = self.classifier.inverse_bbox_regression(bbox_reg, nms)\n",
    "        return cls, predict, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "img_size=image1.shape\n",
    "anchor_boxes=anchor_boxes\n",
    "k=5*5\n",
    "n_sample=32\n",
    "backbone='resnet50'\n",
    "rpn_lambda=10**3\n",
    "pool_size=7\n",
    "num_rois=128\n",
    "batch_size=batch_size\n",
    "classifier_lambda=10\n",
    "\n",
    "frcnn = Faster_RCNN(\n",
    "    img_size=img_size, \n",
    "    anchor_boxes=anchor_boxes, \n",
    "    k=k, \n",
    "    n_sample=n_sample, \n",
    "    backbone=backbone,\n",
    "    rpn_lambda=rpn_lambda, \n",
    "    pool_size=pool_size,\n",
    "    num_rois=num_rois,\n",
    "    batch_size=batch_size,\n",
    "    classifier_lambda=classifier_lambda\n",
    ")\n",
    "# frcnn.load_weights(\"./frcnn\")\n",
    "frcnn.rpn.load_weights('./rpn')\n",
    "\n",
    "# frcnn.save_weights(\"./frcnn\")\n",
    "# frcnn.classifier.save_weights(\"./frcnn_classifier\")\n",
    "# frcnn.rpn.save_weights(\"./frcnn_rpn\")\n",
    "\n",
    "frcnn.compile(\n",
    "    rpn_optimizer = tf.keras.optimizers.Adam(lr=0.01),\n",
    "    classifier_optimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frcnn_train_step(model, train_dataset, train_stage, epochs=1, valid_dataset=None, change_lr=False, rpn_lr=None, cls_lr=None):\n",
    "    if change_lr:\n",
    "        if rpn_lr:\n",
    "            tf.keras.backend.set_value(model.rpn.optimizer.learning_rate, rpn_lr)\n",
    "        if cls_lr:\n",
    "            tf.keras.backend.set_value(model.classifier.optimizer.learning_rate, cls_lr)\n",
    "\n",
    "    if train_stage == 1:\n",
    "        print('Train RPNs \\n')\n",
    "        model.rpn.trainable = True\n",
    "        model.classifier.trainable = False\n",
    "    elif train_stage == 2:\n",
    "        print('Train Fast R-CNN using the proposals from RPNs \\n')\n",
    "        model.rpn.trainable = False\n",
    "        model.rpn.base_model.trainable = True\n",
    "        model.classifier.trainable = True\n",
    "    elif train_stage == 3:\n",
    "        print('Fix the shared convolutional layers and fine-tune unique layers to RPN \\n')\n",
    "        model.rpn.trainable = True\n",
    "        model.rpn.base_model.trainable = False\n",
    "        model.classifier.trainable = False\n",
    "    elif train_stage == 4:\n",
    "        print('Fine-tune unique layers to Fast R-CNN \\n')\n",
    "        model.rpn.trainable = False\n",
    "        model.classifier.trainable = True\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"epoch {epoch+1}/{epochs}\")\n",
    "        display_loss = display(\"Training loss (for one batch) at step 0 : 0\", display_id=True)\n",
    "        for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "            y_cls_rpn = y_batch_train[0]\n",
    "            y_reg_rpn = y_batch_train[1]\n",
    "            gts = y_batch_train[2]\n",
    "            mask = y_batch_train[3]\n",
    "            \n",
    "            if train_stage == 1 or train_stage == 3:\n",
    "                result = model.rpn.train_step((x_batch_train, (y_cls_rpn, y_reg_rpn)))\n",
    "                losses = result['rpn_loss'].numpy()\n",
    "            else:\n",
    "                scores, rps, feature_map = model.rpn(x_batch_train)\n",
    "                rps = model.rpn.inverse_bbox_regression(rps)\n",
    "                candidate_area, scores = model.get_candidate((scores, rps, model.n_train_pre_nms))\n",
    "                nms = model.get_nms((candidate_area, scores, model.n_train_post_nms))\n",
    "                box_labels, cls_labels, nms = classifier_label_generator(nms, gts)\n",
    "                rois = model.roipool((feature_map, nms))\n",
    "                result = model.classifier.train_step(((rois, nms), (cls_labels, box_labels, mask)))\n",
    "                losses = result['classifier_loss'].numpy()\n",
    "\n",
    "            display_loss.update(f\"Training loss at step {step} : {losses}\")\n",
    "\n",
    "        if valid_dataset is not None:\n",
    "            display_loss_valid = display(\"validation loss : 0\", display_id=True)\n",
    "            for x_batch_test, y_batch_test in valid_dataset:\n",
    "                y_cls_rpn = y_batch_test[0]\n",
    "                y_reg_rpn = y_batch_test[1]\n",
    "                gts = y_batch_test[2]\n",
    "                mask = y_batch_test[3]\n",
    "\n",
    "                if train_stage == 1 or train_stage == 3:\n",
    "                    result = model.rpn.train_step((x_batch_test, (y_cls_rpn, y_reg_rpn)))\n",
    "                    losses = result['rpn_loss'].numpy()\n",
    "                else:\n",
    "                    scores, rps, feature_map = model.rpn(x_batch_test)\n",
    "                    rps = model.rpn.inverse_bbox_regression(rps)\n",
    "                    candidate_area, scores = model.get_candidate((scores, rps, model.n_test_pre_nms))\n",
    "                    nms = model.get_nms((candidate_area, scores, model.n_test_post_nms))\n",
    "                    box_labels, cls_labels, nms = classifier_label_generator(nms, gts)\n",
    "                    rois = model.roipool((feature_map, nms))\n",
    "                    result = model.classifier.train_step(((rois, nms), (cls_labels, box_labels, mask)))\n",
    "                    losses = result['classifier_loss'].numpy()\n",
    "                \n",
    "            display_loss_valid.update(f\"validation loss : {losses}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1, 2, 3, 4]:\n",
    "    frcnn = frcnn_train_step(\n",
    "        model=frcnn, \n",
    "        train_dataset=train_dataset, \n",
    "        train_stage=i,\n",
    "        epochs=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frcnn.save_weights(\"./frcnn\")\n",
    "# frcnn.classifier.save_weights(\"./frcnn_classifier\")\n",
    "# frcnn.rpn.save_weights(\"./frcnn_rpn\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "240.188px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 363,
   "position": {
    "height": "40px",
    "left": "869px",
    "right": "20px",
    "top": "98px",
    "width": "478px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
